{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def conv_layer(prev_layer, K, F, S):\n",
    "    width_prev_layer = int(prev_layer.get_shape()[3])\n",
    "    Weight_mat = weight_variable([F, F, width_prev_layer, K])\n",
    "    return tf.nn.conv2d(prev_layer, Weight_mat, strides=[1, S, S, 1], padding='SAME') + bias_variable([K])\n",
    "\n",
    "def conv_pool_layer(prev_layer, K, F, S):\n",
    "    \"\"\"\n",
    "    Convolutional Layer and followed by a pool 2x2 layer\n",
    "\n",
    "    input:\n",
    "    prev_layer: The previous layer\n",
    "    K: Number of filters\n",
    "    F: Spatial extent (width of each filter)\n",
    "    S: The stride\n",
    "\n",
    "    ouput:\n",
    "    A layer with filters\n",
    "    Let W be the width of prev. layer\n",
    "    the output size is W/(2*S)\n",
    "    \"\"\"\n",
    "    activation_layer = tf.nn.relu(conv_layer(prev_layer, K, F, S))\n",
    "    return max_pool_2x2(activation_layer)\n",
    "\n",
    "def Full_conect_layer(prev_layer, activation, K):\n",
    "    \"\"\"\n",
    "    transform the previous layer to a \"flat\" matrix\n",
    "    And then fully connect to the next layer\n",
    "\n",
    "    input:\n",
    "    prev_layer: The previous layer\n",
    "    activation: ghd activation function of the nervous\n",
    "    K: size of the output layer \n",
    "\n",
    "    ouput:\n",
    "    a \"flat\" matrix with size K\n",
    "    \"\"\"\n",
    "    sz_prev = int(reduce(lambda x,y: x*y, prev_layer.get_shape()[1:]))\n",
    "    flat = tf.reshape(prev_layer, [-1, sz_prev])\n",
    "    Weight = weight_variable([sz_prev, K])\n",
    "    Bias = bias_variable([K])\n",
    "    return activation(tf.matmul(flat, Weight) + Bias)\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "cp1 = conv_pool_layer(x_image, 32, 5, 1)\n",
    "cp2 = conv_pool_layer(cp1, 64, 5, 1)\n",
    "\n",
    "fc1 = Full_conect_layer(cp2, tf.nn.relu, 1024)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "fc1_drop = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "y_conv = Full_conect_layer(fc1_drop, tf.nn.softmax, 10)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.98\n",
      "step 200, training accuracy 0.9\n",
      "step 300, training accuracy 0.88\n",
      "step 400, training accuracy 1\n",
      "test accuracy 0.9439\n",
      "Total Training Time: 108.543915033\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "start_train_time = time.time()\n",
    "for i in range(500):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict = {\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "end_train_time = time.time()\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "print \"Total Training Time:\",(end_train_time - start_train_time)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
