{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time, random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.scalar_summary('mean/' + name, mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.scalar_summary('stddev/' + name, stddev)\n",
    "        tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "        tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "        tf.histogram_summary(name, var)\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=\"weight\")\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=\"bias\")\n",
    "\n",
    "def max_pool_2x2(x, name = \"\"):\n",
    "    name = name if name != \"\" else 'max_pool_' + str(random.randint(1, 1 << 30))\n",
    "    with tf.name_scope(name):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name = \"activation\")\n",
    "\n",
    "def conv_layer(prev_layer, n_output, filter_width, activation = tf.identity, stride = 1, name = \"\"):\n",
    "    name = name if name != \"\" else 'conv_' + str(random.randint(1, 1 << 30))\n",
    "    \n",
    "    width_prev_layer = int(prev_layer.get_shape()[3])\n",
    "    with tf.name_scope(name):\n",
    "        Weight_mat = weight_variable([filter_width, filter_width, width_prev_layer, n_output])\n",
    "        variable_summaries(Weight_mat, name+'/weights')\n",
    "        res = tf.nn.conv2d(\n",
    "            prev_layer, \n",
    "            Weight_mat, \n",
    "            strides=[1, stride, stride, 1], \n",
    "            padding='SAME') + bias_variable([n_output])\n",
    "        return activation(res)\n",
    "\n",
    "def full_connect_layer(prev_layer, n_output, activation, name = \"\"):\n",
    "    \"\"\"\n",
    "    transform the previous layer to a \"flat\" matrix\n",
    "    And then fully connect to the next layer\n",
    "\n",
    "    input:\n",
    "    prev_layer: The previous layer\n",
    "    activation: ghd activation function of the nervous\n",
    "    K: size of the output layer \n",
    "\n",
    "    ouput:\n",
    "    a \"flat\" matrix with size K\n",
    "    \"\"\"\n",
    "    name = name if name != \"\" else 'fc_' + str(random.randint(1, 1 << 30))\n",
    "    with tf.name_scope(name):\n",
    "        sz_prev = int(reduce(lambda x,y: x*y, prev_layer.get_shape()[1:]))\n",
    "        flat = tf.reshape(prev_layer, [-1, sz_prev])\n",
    "        Weight = weight_variable([sz_prev, n_output])\n",
    "        Bias = bias_variable([n_output])\n",
    "        return activation(tf.matmul(flat, Weight) + Bias, name = \"activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 224, 224, 3], name=\"x-input\")\n",
    "sz_y = 17\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, sz_y], name=\"y-input\")\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "network = conv_layer(x, 64, 3, tf.nn.relu)\n",
    "network = conv_layer(network, 64, 3, tf.nn.relu)\n",
    "network = max_pool_2x2(network)\n",
    "\n",
    "network = conv_layer(network, 128, 3, tf.nn.relu)\n",
    "network = conv_layer(network, 128, 3, tf.nn.relu)\n",
    "network = max_pool_2x2(network)\n",
    "\n",
    "network = conv_layer(network, 256, 3, tf.nn.relu)\n",
    "network = conv_layer(network, 256, 3, tf.nn.relu)\n",
    "network = conv_layer(network, 256, 3, tf.nn.relu)\n",
    "network = max_pool_2x2(network)\n",
    "\n",
    "network = conv_layer(network, 512, 3, tf.nn.relu)\n",
    "network = conv_layer(network, 512, 3, tf.nn.relu)\n",
    "network = conv_layer(network, 512, 3, tf.nn.relu)\n",
    "network = max_pool_2x2(network)\n",
    "\n",
    "network = conv_layer(network, 512, 3, tf.nn.relu)\n",
    "network = conv_layer(network, 512, 3, tf.nn.relu)\n",
    "network = conv_layer(network, 512, 3, tf.nn.relu)\n",
    "network = max_pool_2x2(network)\n",
    "\n",
    "network = full_connect_layer(network, 4096, tf.nn.relu)\n",
    "network = tf.nn.dropout(network, keep_prob)\n",
    "network = full_connect_layer(network, 4096, tf.nn.relu)\n",
    "network = tf.nn.dropout(network, keep_prob)\n",
    "network = full_connect_layer(network, sz_y, tf.nn.softmax)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(network), reduction_indices=[1]))\n",
    "train_step = tf.train.RMSPropOptimizer(1e-3).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(network, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import oxflower17\n",
    "\n",
    "class NP_Dataset(object):\n",
    "    def __init__(self, pX, pY):\n",
    "        self._X = pX\n",
    "        self._Y = pY\n",
    "        assert np.shape(self._X)[0] == np.shape(self._Y)[0]\n",
    "        self._n_sample = np.shape(self._X)[0]\n",
    "        self._index_in_epoch = 0\n",
    "        self._epoch_completed = 0\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._n_sample:\n",
    "            assert batch_size <= self._n_sample\n",
    "            self._epoch_completed += 1\n",
    "            # Shuffle\n",
    "            perm = np.arange(self._n_sample) \n",
    "            np.random.shuffle(perm)\n",
    "            self._X = self._X[perm]\n",
    "            self._Y = self._Y[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "        end = self._index_in_epoch\n",
    "        return self._X[start:end], self._Y[start:end]\n",
    "\n",
    "flower = NP_Dataset(*oxflower17.load_data())\n",
    "# Test\n",
    "# batch = flower.next_batch(32)\n",
    "# batch = flower.next_batch(1000)\n",
    "# batch = flower.next_batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 99, training accuracy 0.0625\n",
      "step 199, training accuracy 0.1875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f25393ed80bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# train_writer.add_summary(summary, i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         train_step.run(feed_dict={\n\u001b[0;32m---> 37\u001b[0;31m                 x: batch[0], y_: batch[1], keep_prob: 0.5})\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mend_train_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Training Time:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_train_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_train_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1551\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \"\"\"\n\u001b[0;32m-> 1553\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3682\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3683\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3684\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# rm this dir before run again\n",
    "# execute: tensorboard --logdir=./CNN_logs\n",
    "# summaries_dir = './VGG16_logs'\n",
    "# tf.scalar_summary('cross_entropy', cross_entropy)\n",
    "# tf.scalar_summary('accuracy', accuracy)\n",
    "# merged = tf.merge_all_summaries()\n",
    "# train_writer = tf.train.SummaryWriter(summaries_dir + '/train', sess.graph)\n",
    "# test_writer = tf.train.SummaryWriter(summaries_dir + '/test')\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "start_train_time = time.time()\n",
    "for i in range(2000):\n",
    "    batch = flower.next_batch(32)\n",
    "    print(\"i = %d\", i)\n",
    "    if i%100 == 99:\n",
    "        # Train\n",
    "        # run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "        # run_metadata = tf.RunMetadata()\n",
    "        # summary, train_accuracy = sess.run([merged, accuracy], feed_dict = {\n",
    "        #         x: batch[0], \n",
    "        #         y_: batch[1],\n",
    "        #         keep_prob: 1.0})\n",
    "        # train_writer.add_summary(summary, i)\n",
    "        # train_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "        train_accuracy = accuracy.eval(feed_dict = {\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        # Test\n",
    "        # summary, test_accuracy = sess.run([merged, accuracy], feed_dict={\n",
    "        #     x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "        # test_writer.add_summary(summary, i)\n",
    "        # print(\"test accuracy %g\"%test_accuracy)\n",
    "    else:  # Record a summary\n",
    "        # summary, _ = sess.run([merged, train_step], feed_dict={\n",
    "        #         x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "        # train_writer.add_summary(summary, i)\n",
    "        train_step.run(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "end_train_time = time.time()\n",
    "print(\"Total Training Time:\",(end_train_time - start_train_time))\n",
    "\n",
    "# train_writer.close()\n",
    "# test_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
